# âœ… ä¿®æ”¹ç‰ˆ ResNet18 è®­ç»ƒä»£ç ï¼Œå¢å¼ºæ³›åŒ–èƒ½åŠ›ï¼Œæé«˜æµ‹è¯•å‡†ç¡®ç‡

import os
import torch
import torch.nn as nn
from torch.utils.data import DataLoader
from torchvision import transforms, models
from dataset_AAT import FashionDataset_AAT
import matplotlib.pyplot as plt

# ----------------------------
# âœ… è®¾ç½®è·¯å¾„å’Œè®¾å¤‡
# ----------------------------
image_path = '/Users/liujiaxiang/Desktop/9444gs/ã€AiDLabã€‘A100/AAT/image'
csv_file = 'train_b.csv'
val_file = 'val_b.csv'
model_path = 'best_model_resnet18_b.pth'
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
print(f"ğŸš€ ä½¿ç”¨è®¾å¤‡ï¼š{device}")

# ----------------------------
# âœ… å›¾åƒé¢„å¤„ç†ï¼ˆåŠ å…¥æ›´ä¸°å¯Œçš„æ•°æ®å¢å¼ºï¼‰
# ----------------------------
train_transform = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.RandomHorizontalFlip(p=0.5),
    transforms.RandomRotation(15),
    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),
    transforms.ToTensor(),
    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
])

val_transform = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
])

# ----------------------------
# âœ… åŠ è½½æ•°æ®
# ----------------------------
train_set = FashionDataset_AAT(csv_file, image_path, transform=train_transform, label_type='sub')
val_set = FashionDataset_AAT(val_file, image_path, transform=val_transform, label_type='sub')
train_loader = DataLoader(train_set, batch_size=32, shuffle=True)
val_loader = DataLoader(val_set, batch_size=64)

num_classes = len(train_set.label2idx)
print(f"ğŸ“Š å­ç±»åˆ«æ•°ï¼š{num_classes}")

# ----------------------------
# âœ… æ¨¡å‹ï¼šResNet18 + Dropout
# ----------------------------
model = models.resnet18(weights=models.ResNet18_Weights.DEFAULT)
num_features = model.fc.in_features
model.fc = nn.Sequential(
    nn.Dropout(0.5),
    nn.Linear(num_features, num_classes)
)
model = model.to(device)

# ----------------------------
# âœ… æŸå¤±å‡½æ•°ã€ä¼˜åŒ–å™¨ + L2 æ­£åˆ™é¡¹
# ----------------------------
criterion = nn.CrossEntropyLoss()
optimizer = torch.optim.Adam(model.parameters(), lr=0.0005, weight_decay=1e-4)

# ----------------------------
# âœ… è®­ç»ƒæ¨¡å‹
# ----------------------------
epochs = 20
best_acc = 0

# âœ… è®°å½•æ¯ä¸€è½®å‡†ç¡®ç‡
train_acc_list = []
val_acc_list = []

for epoch in range(epochs):
    model.train()
    running_loss = 0
    correct_train, total_train = 0, 0

    for images, labels in train_loader:
        images, labels = images.to(device), labels.to(device)
        outputs = model(images)
        loss = criterion(outputs, labels)

        optimizer.zero_grad()
        loss.backward()
        optimizer.step()
        running_loss += loss.item()

        _, predicted = torch.max(outputs, 1)
        correct_train += (predicted == labels).sum().item()
        total_train += labels.size(0)

    train_acc = correct_train / total_train

    # éªŒè¯
    model.eval()
    correct_val, total_val = 0, 0
    with torch.no_grad():
        for images, labels in val_loader:
            images, labels = images.to(device), labels.to(device)
            outputs = model(images)
            _, predicted = torch.max(outputs, 1)
            correct_val += (predicted == labels).sum().item()
            total_val += labels.size(0)

    val_acc = correct_val / total_val

    # âœ… è®°å½•å‡†ç¡®ç‡
    train_acc_list.append(train_acc)
    val_acc_list.append(val_acc)

    print(f"ğŸ“¦ Epoch {epoch+1}/{epochs}, Loss: {running_loss:.4f}, Train Acc: {train_acc:.4f}, Val Acc: {val_acc:.4f}")

    if val_acc > best_acc:
        best_acc = val_acc
        torch.save(model.state_dict(), model_path)
        print("âœ… æœ€ä½³æ¨¡å‹å·²ä¿å­˜")

print("ğŸ‰ è®­ç»ƒå®Œæˆï¼")
