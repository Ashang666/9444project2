import torch
from torch.utils.data import DataLoader
from torchvision import transforms, models
import torch.nn as nn
from dataset_AAT import FashionDataset_AAT

# âœ… è®¾ç½®è·¯å¾„
image_path = '/Users/liujiaxiang/Desktop/9444gs/ã€AiDLabã€‘A100/AAT/image'
test_csv = 'test_b.csv'
model_path = 'best_model_vgg16_b.pth'
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
print(f"ğŸš€ ä½¿ç”¨è®¾å¤‡ï¼š{device}")

# âœ… å›¾åƒé¢„å¤„ç†ï¼ˆå¿…é¡»ä¸è®­ç»ƒä¿æŒä¸€è‡´ï¼‰
transform = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
    transforms.Normalize([0.485, 0.456, 0.406],
                         [0.229, 0.224, 0.225])
])

# âœ… åŠ è½½æµ‹è¯•é›†
test_set = FashionDataset_AAT(test_csv, image_path, transform=transform, label_type='sub')
test_loader = DataLoader(test_set, batch_size=64)
num_classes = len(test_set.label2idx)
idx2label = {v: k for k, v in test_set.label2idx.items()}

# âœ… åŠ è½½æ¨¡å‹ï¼ˆç»“æ„è¦å’Œè®­ç»ƒä¸€è‡´ï¼‰
vgg16 = models.vgg16(weights=None)  # ä¸åŠ è½½é¢„è®­ç»ƒæƒé‡
vgg16.classifier[6] = nn.Sequential(
    nn.Linear(4096, 512),
    nn.ReLU(),
    nn.Dropout(0.5),
    nn.Linear(512, num_classes)
)
model = vgg16.to(device)

# âœ… åŠ è½½è®­ç»ƒå¥½çš„å‚æ•°
model.load_state_dict(torch.load(model_path, map_location=device))
model.eval()

# âœ… æµ‹è¯•è¯„ä¼°
correct, total = 0, 0
with torch.no_grad():
    for images, labels in test_loader:
        images, labels = images.to(device), labels.to(device)
        outputs = model(images)
        _, predicted = torch.max(outputs, 1)
        correct += (predicted == labels).sum().item()
        total += labels.size(0)

acc = correct / total
print(f"\nâœ… æµ‹è¯•é›†å‡†ç¡®ç‡ï¼š{acc:.4f}ï¼ˆå…± {total} å¼ å›¾åƒï¼‰")
